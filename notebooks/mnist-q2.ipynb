{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "import rsatoolbox.rdm.calc\n",
    "import rsatoolbox.data\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import utils  # noqa: E402\n",
    "\n",
    "\n",
    "def sample_images(data_loader, n=5, plot=False):\n",
    "    \"\"\"Samples a specified number of images from a data loader.\"\"\"\n",
    "    imgs, labels = next(iter(data_loader))\n",
    "\n",
    "    imgs_o = []\n",
    "    targets = []\n",
    "    for value in range(10):\n",
    "        imgs_o.append(imgs[np.where(labels == value)][0:n])\n",
    "        targets.append([value] * n)\n",
    "\n",
    "    imgs = torch.cat(imgs_o, dim=0)\n",
    "    targets = torch.tensor(targets).flatten()\n",
    "\n",
    "    if plot:\n",
    "        plt.imshow(\n",
    "            torch.moveaxis(\n",
    "                make_grid(imgs, nrow=n, padding=0, normalize=False, pad_value=0), 0, -1\n",
    "            )\n",
    "        )\n",
    "        plt.title(\"Sampled Test Images (5 of each class)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return imgs, targets\n",
    "\n",
    "\n",
    "def extract_features(model, imgs, return_layers):\n",
    "    \"\"\"Extracts features from specified layers of the model.\"\"\"\n",
    "    if return_layers == \"all\":\n",
    "        # Automatically get the names of all layers in the model\n",
    "        return_layers, _ = get_graph_node_names(model)\n",
    "\n",
    "    print(f\"{return_layers=}\")\n",
    "\n",
    "    # Create the feature extractor\n",
    "    feature_extractor = create_feature_extractor(model, return_nodes=return_layers)\n",
    "    model_features = feature_extractor(imgs)\n",
    "\n",
    "    # Re-key with simple integer indices for easier plotting and add the input layer\n",
    "    final_features = {i: v for i, (k, v) in enumerate(model_features.items())}\n",
    "    final_features[-1] = imgs  # Add input layer with key -1\n",
    "\n",
    "    # Sort the dictionary by layer index to ensure the correct processing order\n",
    "    final_features = dict(sorted(final_features.items()))\n",
    "\n",
    "    return final_features\n",
    "\n",
    "\n",
    "def extract_features_(model, imgs, return_layers):\n",
    "    if isinstance(return_layers, str) and return_layers == \"all\":\n",
    "        # Automatically get the names of all layers in the model\n",
    "        return_layers, _ = get_graph_node_names(model)\n",
    "\n",
    "    print(f\"{return_layers=}\")\n",
    "\n",
    "    # Create the feature extractor\n",
    "    feature_extractor = create_feature_extractor(model, return_nodes=return_layers)\n",
    "    model_features = feature_extractor(imgs)\n",
    "    return model_features\n",
    "\n",
    "\n",
    "def calc_rdms(model_features, method=\"correlation\"):\n",
    "    \"\"\"Calculates representational dissimilarity matrices (RDMs) for model features.\n",
    "\n",
    "    Args:\n",
    "        model_features: A dictionary where keys are layer names and values are features of the layers.\n",
    "        method: The method to calculate RDMs, e.g., 'correlation'. Default is 'correlation'.\n",
    "\n",
    "    Outputs:\n",
    "        rdms: RDMs object containing dissimilarity matrices.\n",
    "        rdms_dict: A dictionary with layer names as keys and their corresponding RDMs as values.\n",
    "    \"\"\"\n",
    "    ds_list = []\n",
    "    for l in range(len(model_features)):\n",
    "        layer = list(model_features.keys())[l]\n",
    "        feats = model_features[layer]\n",
    "\n",
    "        if type(feats) is list:\n",
    "            feats = feats[-1]\n",
    "\n",
    "        feats = feats.cpu()\n",
    "\n",
    "        if len(feats.shape) > 2:\n",
    "            feats = feats.flatten(1)\n",
    "\n",
    "        feats = feats.detach().numpy()\n",
    "        ds = rsatoolbox.data.Dataset(feats, descriptors=dict(layer=layer))\n",
    "        ds_list.append(ds)\n",
    "\n",
    "    rdms = rsatoolbox.rdm.calc.calc_rdm(ds_list, method=method)\n",
    "    rdms_dict = {\n",
    "        list(model_features.keys())[i]: rdms.get_matrices()[i]\n",
    "        for i in range(len(model_features))\n",
    "    }\n",
    "\n",
    "    return rdms, rdms_dict\n",
    "\n",
    "\n",
    "def plot_maps(model_features, model_name):\n",
    "    \"\"\"Plots representational dissimilarity matrices (RDMs) across different layers.\"\"\"\n",
    "    fig = plt.figure(figsize=(14, 4))\n",
    "    fig.suptitle(f\"RDMs across layers for {model_name}\")\n",
    "    gs = fig.add_gridspec(1, len(model_features))\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "\n",
    "    for l, layer in enumerate(model_features.keys()):\n",
    "        map_ = np.squeeze(model_features[layer])\n",
    "\n",
    "        if len(map_.shape) < 2:\n",
    "            side_len = int(np.sqrt(map_.shape[0]))\n",
    "            if side_len * side_len == map_.shape[0]:\n",
    "                map_ = map_.reshape((side_len, side_len))\n",
    "\n",
    "        if np.max(map_) > 0:\n",
    "            map_ = map_ / np.max(map_)\n",
    "\n",
    "        ax = plt.subplot(gs[0, l])\n",
    "        ax_ = ax.imshow(map_, cmap=\"magma_r\")\n",
    "        ax.set_title(f\"Layer: {layer}\")\n",
    "        ax.set_xlabel(\"Input Index\")\n",
    "        if l == 0:\n",
    "            ax.set_ylabel(\"Input Index\")\n",
    "\n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.01, 0.7])\n",
    "    cbar = fig.colorbar(ax_, cax=cbar_ax)\n",
    "    cbar.set_label(\"Dissimilarity\", rotation=270, labelpad=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def create_model(n_classes, latent_dim=84):\n",
    "    \"\"\"Creates a fresh instance of the CNN architecture.\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Sequential(nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)),\n",
    "        nn.Sequential(nn.Conv2d(6, 16, 5), nn.ReLU(), nn.MaxPool2d(2)),\n",
    "        nn.Sequential(nn.Flatten(), nn.Linear(16 * 5 * 5, 120), nn.ReLU()),\n",
    "        nn.Sequential(nn.Linear(120, latent_dim), nn.ReLU()),\n",
    "        nn.Sequential(nn.Linear(latent_dim, n_classes)),\n",
    "    )\n",
    "\n",
    "\n",
    "# Config\n",
    "batch_size = 32\n",
    "n_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load models\n",
    "bp_model = models.LeNet5(n_classes=10, latent_dim=84, act_fn=\"relu\")\n",
    "bp_model.load_state_dict(torch.load(\"../results/backprop-model.pth\"))\n",
    "bp_model.eval().to(device)\n",
    "\n",
    "ff_model = models.FFLeNet5(n_classes=10, latent_dim=84)\n",
    "ff_model.load_state_dict(torch.load(\"../results/ff-model.pth\"))\n",
    "ff_model.eval().to(device)\n",
    "\n",
    "pc_model = create_model(n_classes=n_classes)\n",
    "pc_model.load_state_dict(torch.load(\"../results/pc-model.pth\"))\n",
    "pc_model.eval().to(device)\n",
    "\n",
    "# Load data\n",
    "_, _, test_loader = utils.load_mnist_data(batch_size)\n",
    "class_names = [str(i) for i in range(n_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d462f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_map = {\n",
    "#     '0.0': 'conv1',\n",
    "#     '0.1': 'relu',\n",
    "#     '0.2': 'pool1',\n",
    "#     '1.0': 'conv2',\n",
    "#     '1.1': 'relu_1',\n",
    "#     '1.2': 'pool2',\n",
    "#     '2.0': 'flatten',\n",
    "#     '2.1': 'fc1',\n",
    "#     '2.2': 'relu_2',\n",
    "#     '3.0': 'fc2',\n",
    "#     '3.1': 'relu_3',\n",
    "#     '4.0': 'output'\n",
    "# }\n",
    "\n",
    "train_nodes, val_nodes = get_graph_node_names(bp_model)\n",
    "print(f\"{train_nodes=}\")\n",
    "print(f\"{val_nodes=}\\n\")\n",
    "\n",
    "train_nodes, val_nodes = get_graph_node_names(ff_model)\n",
    "print(f\"{train_nodes=}\")\n",
    "print(f\"{val_nodes=}\\n\")\n",
    "\n",
    "train_nodes, val_nodes = get_graph_node_names(pc_model)\n",
    "print(f\"{train_nodes=}\")\n",
    "print(f\"{val_nodes=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: it's not returning 5 samples per class\n",
    "imgs, targets = sample_images(test_loader, n=5, plot=True)\n",
    "\n",
    "print(\"Extracting features (backprop)\")\n",
    "layer_names = [\"conv1\", \"conv2\", \"conv3\", \"fc1\", \"fc2\"]\n",
    "# layer_names = [\"pool1\", \"pool2\", \"flatten\", \"relu_3\", \"fc2\"]\n",
    "bp_features = extract_features(bp_model, imgs.to(device), return_layers=layer_names)\n",
    "\n",
    "# FIXME: input[32, 1, 32, 32] to have 11 channels, but got 1 channels instead\n",
    "# print(\"\\nExtracting features (forward-forward)\")\n",
    "# layer_names = [\"conv1.conv\", \"conv2.conv\", \"conv3.conv\", \"fc1.linear\", \"fc2.linear\"]\n",
    "# ff_features = extract_features(ff_model, imgs.to(device), return_layers=layer_names)\n",
    "\n",
    "print(\"\\nExtracting features (predictive coding)\")\n",
    "layer_names = [0, 1, 2, 3, 4]\n",
    "pc_features = extract_features_(pc_model, imgs.to(device), return_layers=layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69481f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdms_bp, rdms_dict_bp = calc_rdms(bp_features)\n",
    "plot_maps(rdms_dict_bp, \"Backpropagation\")\n",
    "\n",
    "rdms_pc, rdms_dict_pc = calc_rdms(pc_features)\n",
    "plot_maps(rdms_dict_pc, \"Predictive Coding\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
