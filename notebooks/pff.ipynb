{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Hyperparameters\n",
    "label_dim = 10\n",
    "hidden_dim = 256\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "timesteps = 5\n",
    "lr = 1e-3\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # Keep image as (1, 28, 28)\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "# One-hot encoding\n",
    "\n",
    "\n",
    "def one_hot(labels, num_classes=10):\n",
    "    return F.one_hot(labels, num_classes).float()\n",
    "\n",
    "\n",
    "# PFF with CNN front-end\n",
    "\n",
    "\n",
    "class PFF_CNN(nn.Module):\n",
    "    def __init__(self, label_dim=10, hidden_size=256):\n",
    "        super(PFF_CNN, self).__init__()\n",
    "        # Convolutional layers (LeNet-like)\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)  # C1\n",
    "        self.pool1 = nn.AvgPool2d(2, 2)  # S2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # C3\n",
    "        self.pool2 = nn.AvgPool2d(2, 2)  # S4\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=3)  # C5 - Reduced kernel size\n",
    "\n",
    "        self.feature_dim = (\n",
    "            120 * 2 * 2\n",
    "        )  # Final flattened CNN output after conv3 (kernel 3)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        # Representation & generative pathways\n",
    "        self.rep = nn.Linear(self.feature_dim + label_dim + hidden_size, hidden_size)\n",
    "        self.gen = nn.Linear(hidden_size, self.feature_dim + label_dim)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        return x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "    def forward_step(self, x, y_onehot, h):\n",
    "        feats = self.extract_features(x)\n",
    "        u = torch.cat([feats, y_onehot, h], dim=1)\n",
    "        h_pred = torch.tanh(self.rep(u))\n",
    "        recon = torch.sigmoid(self.gen(h_pred))\n",
    "        return h_pred, recon\n",
    "\n",
    "    def compute_goodness(self, h):\n",
    "        return torch.sum(h**2, dim=1)\n",
    "\n",
    "    def forward(self, x, y_onehot, h):\n",
    "        return self.forward_step(x, y_onehot, h)\n",
    "\n",
    "\n",
    "# Instantiate model and optimizers\n",
    "model = PFF_CNN(label_dim, hidden_dim).to(device)\n",
    "optimizer_rep = torch.optim.Adam(model.rep.parameters(), lr=lr)\n",
    "optimizer_gen = torch.optim.Adam(model.gen.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "print(\"Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pos = one_hot(y).to(device)\n",
    "\n",
    "        # Negative (wrong) labels\n",
    "        y_neg_idx = torch.randint(0, 10, y.shape, device=device)\n",
    "        y_neg_idx[y_neg_idx == y] = (y_neg_idx[y_neg_idx == y] + 1) % 10\n",
    "        y_neg = one_hot(y_neg_idx).to(device)\n",
    "\n",
    "        # Positive phase\n",
    "        h_pos = torch.zeros(x.size(0), hidden_dim, device=device)\n",
    "        for _ in range(timesteps):\n",
    "            h_pos, recon_pos = model(x, y_pos, h_pos)\n",
    "        g_pos = model.compute_goodness(h_pos)\n",
    "\n",
    "        # Negative phase\n",
    "        h_neg = torch.zeros(x.size(0), hidden_dim, device=device)\n",
    "        for _ in range(timesteps):\n",
    "            h_neg, recon_neg = model(x, y_neg, h_neg)\n",
    "        g_neg = model.compute_goodness(h_neg)\n",
    "\n",
    "        # Losses\n",
    "        loss_rep = F.softplus(g_neg - g_pos).mean()\n",
    "        recon_target = torch.cat([model.extract_features(x).detach(), y_pos], dim=1)\n",
    "        loss_gen = F.mse_loss(recon_pos, recon_target)\n",
    "\n",
    "        total_batch_loss = loss_rep + loss_gen\n",
    "        optimizer_rep.zero_grad()\n",
    "        optimizer_gen.zero_grad()\n",
    "        total_batch_loss.backward()\n",
    "        optimizer_rep.step()\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        total_loss += total_batch_loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation loop\n",
    "print(\"Evaluating...\")\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        batch_size = x.size(0)\n",
    "        goodness_scores = torch.zeros(batch_size, 10, device=device)\n",
    "\n",
    "        for label in range(10):\n",
    "            y_oh = one_hot(\n",
    "                torch.full((batch_size,), label, device=device, dtype=torch.long)\n",
    "            )\n",
    "            h = torch.zeros(batch_size, hidden_dim, device=device)\n",
    "            for _ in range(timesteps):\n",
    "                h, _ = model(x, y_oh, h)\n",
    "            goodness_scores[:, label] = model.compute_goodness(h)\n",
    "\n",
    "        preds = goodness_scores.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCnaHMUEV7Vs",
    "outputId": "c13cee06-0686-4fce-98a2-c46cf1648b62"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cpu\n",
      "Training...\n",
      "Epoch 1/10, Loss: 0.2418\n",
      "Epoch 2/10, Loss: 0.1150\n",
      "Epoch 3/10, Loss: 0.0943\n",
      "Epoch 4/10, Loss: 0.0767\n",
      "Epoch 5/10, Loss: 0.0662\n",
      "Epoch 6/10, Loss: 0.0654\n",
      "Epoch 7/10, Loss: 0.0615\n",
      "Epoch 8/10, Loss: 0.0568\n",
      "Epoch 9/10, Loss: 0.0537\n",
      "Epoch 10/10, Loss: 0.0498\n",
      "Evaluating...\n",
      "Test Accuracy: 91.33%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "pejH80o4hq4u"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
