{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.651432Z",
     "iopub.status.busy": "2025-07-21T11:41:22.651076Z",
     "iopub.status.idle": "2025-07-21T11:41:22.655948Z",
     "shell.execute_reply": "2025-07-21T11:41:22.655154Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.651408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Torch2PC Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.658560Z",
     "iopub.status.busy": "2025-07-21T11:41:22.658387Z",
     "iopub.status.idle": "2025-07-21T11:41:22.670493Z",
     "shell.execute_reply": "2025-07-21T11:41:22.669806Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.658546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from Torch2PC import TorchSeq2PC as T2PC\n",
    "except ImportError:\n",
    "    print(\"Cloning Torch2PC repository...\")\n",
    "    import subprocess\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"git\", \"clone\", \"-q\", \"https://github.com/RobertRosenbaum/Torch2PC.git\"]\n",
    "    )\n",
    "    from Torch2PC import TorchSeq2PC as T2PC\n",
    "print(\"Torch2PC imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from train import T2PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.671999Z",
     "iopub.status.busy": "2025-07-21T11:41:22.671571Z",
     "iopub.status.idle": "2025-07-21T11:41:22.686853Z",
     "shell.execute_reply": "2025-07-21T11:41:22.686292Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.671974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.687641Z",
     "iopub.status.busy": "2025-07-21T11:41:22.687475Z",
     "iopub.status.idle": "2025-07-21T11:41:22.700343Z",
     "shell.execute_reply": "2025-07-21T11:41:22.699680Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.687627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Code will run on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.702103Z",
     "iopub.status.busy": "2025-07-21T11:41:22.701912Z",
     "iopub.status.idle": "2025-07-21T11:41:22.714563Z",
     "shell.execute_reply": "2025-07-21T11:41:22.713915Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.702089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    \"\"\"Load and preprocess the MNIST dataset.\"\"\"\n",
    "    # Define pre process\n",
    "    mnist_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((32, 32)),  # resize from 28x28\n",
    "            transforms.ToTensor(),  #  Converts the image to PyTorch tensors\n",
    "            transforms.Normalize(\n",
    "                (0.1307,), (0.3081,)\n",
    "            ),  # Normalize pixel values using the M and DE of the MNIST dataset. This helps stabilize training\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Download the data (train and test)\n",
    "    train_val_dataset = torchvision.datasets.MNIST(\n",
    "        root=\"./data\", train=True, transform=mnist_transform, download=True\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root=\"./data\", train=False, transform=mnist_transform, download=True\n",
    "    )\n",
    "    # Split train data into train (90%) and validation (10%)\n",
    "    train_size = int(0.9 * len(train_val_dataset))\n",
    "    val_size = len(train_val_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        train_val_dataset, [train_size, val_size]\n",
    "    )\n",
    "    # Define DataLoader instances with proper BATCH_SIZE and shuffle=True to prevent the model from learning the order of the data\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    # Stablish the class names (0 to 9)\n",
    "    class_names = [str(i) for i in range(10)]\n",
    "    return train_loader, val_loader, test_loader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.715340Z",
     "iopub.status.busy": "2025-07-21T11:41:22.715113Z",
     "iopub.status.idle": "2025-07-21T11:41:22.732101Z",
     "shell.execute_reply": "2025-07-21T11:41:22.731493Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.715319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "LATENT_DIM = 84\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "# Predictive Coding Specific Hyperparameters\n",
    "N_INFERENCE_STEPS = 5\n",
    "INFERENCE_LEARNING_RATE = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.733025Z",
     "iopub.status.busy": "2025-07-21T11:41:22.732832Z",
     "iopub.status.idle": "2025-07-21T11:41:22.746852Z",
     "shell.execute_reply": "2025-07-21T11:41:22.746285Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.733010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Creates a fresh instance of the CNN architecture.\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Sequential(nn.Conv2d(1, 6, 5), nn.ReLU(), nn.MaxPool2d(2, 2)),\n",
    "        nn.Sequential(nn.Conv2d(6, 16, 5), nn.ReLU(), nn.MaxPool2d(2)),\n",
    "        nn.Sequential(nn.Flatten(), nn.Linear(16 * 5 * 5, 120), nn.ReLU()),\n",
    "        nn.Sequential(nn.Linear(120, LATENT_DIM), nn.ReLU()),\n",
    "        nn.Sequential(nn.Linear(LATENT_DIM, NUM_CLASSES)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:41:22.842548Z",
     "iopub.status.busy": "2025-07-21T11:41:22.841957Z",
     "iopub.status.idle": "2025-07-21T11:41:22.851779Z",
     "shell.execute_reply": "2025-07-21T11:41:22.850908Z",
     "shell.execute_reply.started": "2025-07-21T11:41:22.842521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model_backprop(model, train_loader, val_loader, num_epochs=NUM_EPOCHS):\n",
    "    \"\"\"Train the CNN model using standard backpropagation.\"\"\"\n",
    "    history = {\n",
    "        \"train_losses\": [],\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_accuracies\": [],\n",
    "        \"epoch_times\": [],\n",
    "        \"total_time\": 0.0,\n",
    "    }\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(f\"\\nStarting standard backpropagation training...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss, correct_predictions, total_samples = 0.0, 0, 0\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)  # Forward Pass\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()  # Backward Pass\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "        history[\"train_losses\"].append(running_loss / len(train_loader))\n",
    "        history[\"train_accuracies\"].append(100.0 * correct_predictions / total_samples)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == targets).sum().item()\n",
    "\n",
    "        history[\"val_losses\"].append(val_loss / len(val_loader))\n",
    "        history[\"val_accuracies\"].append(100.0 * val_correct / val_total)\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "        history[\"epoch_times\"].append(epoch_duration)\n",
    "\n",
    "        print(\n",
    "            (\n",
    "                f\"Epoch [{epoch+1:02d}/{num_epochs}] -> \"\n",
    "                f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n",
    "                f\"Train Acc: {history['train_accuracies'][-1]:.2f}% | \"\n",
    "                f\"Val Loss: {history['val_losses'][-1]:.4f}, \"\n",
    "                f\"Val Acc: {history['val_accuracies'][-1]:.2f}% | \"\n",
    "                f\"Time: {epoch_duration:.2f}s\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    total_end_time = time.time()\n",
    "    history[\"total_time\"] = total_end_time - total_start_time\n",
    "\n",
    "    print(\"\\nBackpropagation training completed!\")\n",
    "    print(f\"Total training time: {history['total_time']:.2f} seconds ⏱️\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:58:00.693781Z",
     "iopub.status.busy": "2025-07-21T11:58:00.693155Z",
     "iopub.status.idle": "2025-07-21T11:58:00.704225Z",
     "shell.execute_reply": "2025-07-21T11:58:00.703566Z",
     "shell.execute_reply.started": "2025-07-21T11:58:00.693756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model_pc(model, train_loader, val_loader, num_epochs=NUM_EPOCHS):\n",
    "    \"\"\"Train the CNN model using Predictive Coding (Strict).\"\"\"\n",
    "    history = {\n",
    "        \"train_losses\": [],\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_accuracies\": [],\n",
    "        \"epoch_times\": [],\n",
    "        \"total_time\": 0.0,\n",
    "    }\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(f\"\\nStarting Predictive Coding training...\")\n",
    "    print(\n",
    "        f\"Using eta={INFERENCE_LEARNING_RATE} and n={N_INFERENCE_STEPS} inference iterations.\"\n",
    "    )\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss, correct_predictions, total_samples = 0.0, 0, 0\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            targets_onehot = F.one_hot(targets, num_classes=NUM_CLASSES).float()\n",
    "\n",
    "            vhat, loss, _, _, _ = T2PC.PCInfer(\n",
    "                model,\n",
    "                criterion,\n",
    "                data,\n",
    "                targets_onehot,\n",
    "                \"Strict\",\n",
    "                eta=INFERENCE_LEARNING_RATE,\n",
    "                n=N_INFERENCE_STEPS,\n",
    "            )\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(vhat[-1].data, 1)\n",
    "            total_samples += targets.size(0)\n",
    "            correct_predictions += (predicted_labels == targets).sum().item()\n",
    "\n",
    "        history[\"train_losses\"].append(running_loss / len(train_loader))\n",
    "        history[\"train_accuracies\"].append(100.0 * correct_predictions / total_samples)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(data)\n",
    "                targets_onehot = F.one_hot(targets, num_classes=NUM_CLASSES).float()\n",
    "\n",
    "                loss = criterion(outputs, targets_onehot)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == targets).sum().item()\n",
    "\n",
    "        history[\"val_losses\"].append(val_loss / len(val_loader))\n",
    "        history[\"val_accuracies\"].append(100.0 * val_correct / val_total)\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "        history[\"epoch_times\"].append(epoch_duration)\n",
    "\n",
    "        print(\n",
    "            (\n",
    "                f\"Epoch [{epoch+1:02d}/{num_epochs}] -> \"\n",
    "                f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n",
    "                f\"Train Acc: {history['train_accuracies'][-1]:.2f}% | \"\n",
    "                f\"Val Loss: {history['val_losses'][-1]:.4f}, \"\n",
    "                f\"Val Acc: {history['val_accuracies'][-1]:.2f}% | \"\n",
    "                f\"Time: {epoch_duration:.2f}s\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    total_end_time = time.time()\n",
    "    history[\"total_time\"] = total_end_time - total_start_time\n",
    "\n",
    "    print(\"\\nPredictive Coding training completed!\")\n",
    "    print(f\"Total training time: {history['total_time']:.2f} seconds ⏱️\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T11:58:13.924815Z",
     "iopub.status.busy": "2025-07-21T11:58:13.924174Z",
     "iopub.status.idle": "2025-07-21T12:14:06.523890Z",
     "shell.execute_reply": "2025-07-21T12:14:06.523288Z",
     "shell.execute_reply.started": "2025-07-21T11:58:13.924794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Predictive Coding training...\n",
      "Using eta=5e-05 and n=5 inference iterations.\n",
      "------------------------------------------------------------\n",
      "Epoch [01/15] -> Train Loss: 0.0400, Train Acc: 81.49% | Val Loss: 0.0276, Val Acc: 88.50% | Time: 40.74s\n",
      "Epoch [02/15] -> Train Loss: 0.0243, Train Acc: 89.51% | Val Loss: 0.0225, Val Acc: 90.35% | Time: 42.73s\n",
      "Epoch [03/15] -> Train Loss: 0.0208, Train Acc: 90.95% | Val Loss: 0.0204, Val Acc: 91.15% | Time: 36.47s\n",
      "Epoch [04/15] -> Train Loss: 0.0193, Train Acc: 91.81% | Val Loss: 0.0193, Val Acc: 91.80% | Time: 34.48s\n",
      "Epoch [05/15] -> Train Loss: 0.0184, Train Acc: 92.35% | Val Loss: 0.0185, Val Acc: 92.23% | Time: 37.26s\n",
      "Epoch [06/15] -> Train Loss: 0.0178, Train Acc: 92.80% | Val Loss: 0.0180, Val Acc: 92.70% | Time: 36.13s\n",
      "Epoch [07/15] -> Train Loss: 0.0173, Train Acc: 92.98% | Val Loss: 0.0175, Val Acc: 92.88% | Time: 34.69s\n",
      "Epoch [08/15] -> Train Loss: 0.0169, Train Acc: 93.20% | Val Loss: 0.0174, Val Acc: 92.90% | Time: 35.81s\n",
      "Epoch [09/15] -> Train Loss: 0.0166, Train Acc: 93.37% | Val Loss: 0.0168, Val Acc: 93.10% | Time: 35.01s\n",
      "Epoch [10/15] -> Train Loss: 0.0163, Train Acc: 93.55% | Val Loss: 0.0167, Val Acc: 93.20% | Time: 35.05s\n",
      "Epoch [11/15] -> Train Loss: 0.0160, Train Acc: 93.71% | Val Loss: 0.0169, Val Acc: 93.33% | Time: 36.15s\n",
      "Epoch [12/15] -> Train Loss: 0.0158, Train Acc: 93.86% | Val Loss: 0.0164, Val Acc: 93.45% | Time: 36.35s\n",
      "Epoch [13/15] -> Train Loss: 0.0155, Train Acc: 93.99% | Val Loss: 0.0160, Val Acc: 93.50% | Time: 36.67s\n",
      "Epoch [14/15] -> Train Loss: 0.0154, Train Acc: 94.07% | Val Loss: 0.0158, Val Acc: 93.62% | Time: 37.76s\n",
      "Epoch [15/15] -> Train Loss: 0.0152, Train Acc: 94.17% | Val Loss: 0.0156, Val Acc: 93.73% | Time: 38.43s\n",
      "\n",
      "Predictive Coding training completed!\n",
      "Total training time: 553.72 seconds ⏱️\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_loader, val_loader, test_loader, class_names = load_mnist_data()\n",
    "\n",
    "# Backpropagation Run\n",
    "# bp_model = create_model().to(device)\n",
    "# bp_history = train_model_backprop(bp_model, train_loader, val_loader)\n",
    "\n",
    "# Predictive Coding Run\n",
    "pc_model = create_model().to(device)\n",
    "pc_history = train_model_pc(pc_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T12:19:43.121435Z",
     "iopub.status.busy": "2025-07-21T12:19:43.120836Z",
     "iopub.status.idle": "2025-07-21T12:19:43.132386Z",
     "shell.execute_reply": "2025-07-21T12:19:43.131630Z",
     "shell.execute_reply.started": "2025-07-21T12:19:43.121409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_comparison(bp_history, pc_history):\n",
    "    \"\"\"Generates the 2x3 comparison plot matrix.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "    # --- Row 1: Backpropagation Results ---\n",
    "    axes[0, 0].plot(epochs, bp_history[\"train_losses\"], \"b-o\", label=\"Train Loss\")\n",
    "    axes[0, 0].plot(epochs, bp_history[\"val_losses\"], \"r-s\", label=\"Val Loss\")\n",
    "    axes[0, 0].set_title(\"Backpropagation: Loss vs. Epoch\")\n",
    "    axes[0, 0].set_xlabel(\"Epoch\")\n",
    "    axes[0, 0].set_ylabel(\"Loss\")\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(False)\n",
    "\n",
    "    axes[1, 0].plot(\n",
    "        epochs, bp_history[\"train_accuracies\"], \"b-o\", label=\"Train Accuracy\"\n",
    "    )\n",
    "    axes[1, 0].plot(epochs, bp_history[\"val_accuracies\"], \"r-s\", label=\"Val Accuracy\")\n",
    "    axes[1, 0].set_title(\"Backpropagation: Accuracy vs. Epoch\")\n",
    "    axes[1, 0].set_xlabel(\"Epoch\")\n",
    "    axes[1, 0].set_ylabel(\"Accuracy (%)\")\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(False)\n",
    "\n",
    "    # --- Row 2: Predictive Coding Results ---\n",
    "    axes[0, 1].plot(epochs, pc_history[\"train_losses\"], \"b-o\", label=\"Train Loss\")\n",
    "    axes[0, 1].plot(epochs, pc_history[\"val_losses\"], \"r-s\", label=\"Val Loss\")\n",
    "    axes[0, 1].set_title(\"Predictive Coding: Loss vs. Epoch\")\n",
    "    axes[0, 1].set_xlabel(\"Epoch\")\n",
    "    axes[0, 1].set_ylabel(\"Loss\")\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(False)\n",
    "\n",
    "    axes[1, 1].plot(\n",
    "        epochs, pc_history[\"train_accuracies\"], \"b-o\", label=\"Train Accuracy\"\n",
    "    )\n",
    "    axes[1, 1].plot(epochs, pc_history[\"val_accuracies\"], \"r-s\", label=\"Val Accuracy\")\n",
    "    axes[1, 1].set_title(\"Predictive Coding: Accuracy vs. Epoch\")\n",
    "    axes[1, 1].set_xlabel(\"Epoch\")\n",
    "    axes[1, 1].set_ylabel(\"Accuracy (%)\")\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(False)\n",
    "\n",
    "    # --- Row 3: Combined Results ---\n",
    "    axes[0, 2].plot(epochs, bp_history[\"train_losses\"], \"b-o\", label=\"BP Train Loss\")\n",
    "    axes[0, 2].plot(epochs, bp_history[\"val_losses\"], \"r-s\", label=\"BP Val Loss\")\n",
    "    axes[0, 2].plot(epochs, pc_history[\"train_losses\"], \"b--o\", label=\"PC Train Loss\")\n",
    "    axes[0, 2].plot(epochs, pc_history[\"val_losses\"], \"r--s\", label=\"PC Val Loss\")\n",
    "    axes[0, 2].set_title(\"Combined: Loss vs. Epoch\")\n",
    "    axes[0, 2].set_xlabel(\"Epoch\")\n",
    "    axes[0, 2].set_ylabel(\"Loss\")\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(False)\n",
    "\n",
    "    axes[1, 2].plot(epochs, bp_history[\"train_accuracies\"], \"b-o\", label=\"BP Train Acc\")\n",
    "    axes[1, 2].plot(epochs, bp_history[\"val_accuracies\"], \"r-s\", label=\"BP Val Acc\")\n",
    "    axes[1, 2].plot(\n",
    "        epochs, pc_history[\"train_accuracies\"], \"b--o\", label=\"PC Train Acc\"\n",
    "    )\n",
    "    axes[1, 2].plot(epochs, pc_history[\"val_accuracies\"], \"r--s\", label=\"PC Val Acc\")\n",
    "    axes[1, 2].set_title(\"Combined: Accuracy vs. Epoch\")\n",
    "    axes[1, 2].set_xlabel(\"Epoch\")\n",
    "    axes[1, 2].set_ylabel(\"Accuracy (%)\")\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"comparison_plot_2.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T12:20:00.231422Z",
     "iopub.status.busy": "2025-07-21T12:20:00.231122Z",
     "iopub.status.idle": "2025-07-21T12:20:03.145079Z",
     "shell.execute_reply": "2025-07-21T12:20:03.144448Z",
     "shell.execute_reply.started": "2025-07-21T12:20:00.231399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_comparison(bp_history, pc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pc_history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
